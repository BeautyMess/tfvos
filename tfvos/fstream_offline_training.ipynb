{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `FStream` Offline Training\n",
    "\n",
    "This notebook performs offline training of the **flow stream** on the **DAVIS 2016** dataset.\n",
    "\n",
    "MaskRNN's' binary segmentation net is a 2-stream convnet (`astream` and `fstream`):\n",
    "\n",
    "![](img/maskrnn.png)\n",
    "\n",
    "Section \"3.3 Binary Segmentation\" of the MaskRNN paper and \"Figure 2\" are inconsistent when it comes to describing the inputs of the two-stream network. In this implementation, we chose the input of the flow stream `fstream` to be the concatenation of the magnitude of the flow field from <sub>t-1</sub> to I<sub>t</sub> and I<sub>t</sub> to frame I<sub>t+1</sub> and the warped prediction of the previous frame's segmentation mask b<sub>t-1</sub>, denoted as φ<sub>t-1,t</sub>(b<sub>t-1</sub>). The warping function φ<sub>t-1,t</sub>(.) transforms the input based on the optical flow fields from frame I<sub>t-1</sub> to frame I<sub>t</sub>. The `FStream` network takes 3-channel inputs (||φ<sub>t-1,t</sub>||, ||φ<sub>t,t+1</sub>||, φ<sub>t-1,t</sub>(b<sub>t-1</sub>)):\n",
    "\n",
    "The offline training of the `AStream` is done using a **3-channel input** VGG16 network pre-trained on ImageNet:\n",
    "\n",
    "![](img/osvos_parent.png)\n",
    "\n",
    "\n",
    "To monitor training, run:\n",
    "```\n",
    "tensorboard --logdir E:\\repos\\tf-video-seg\\tfvos\\models\\fstream_parent\n",
    "http://localhost:6006\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fstream_offline_training.ipynb\n",
    "\n",
    "FStream offline trainer\n",
    "\n",
    "Written by Phil Ferriere\n",
    "\n",
    "Licensed under the MIT License (see LICENSE for details)\n",
    "\n",
    "Based on:\n",
    "  - https://github.com/scaelles/OSVOS-TensorFlow/blob/master/osvos_parent_demo.py\n",
    "    Written by Sergi Caelles (scaelles@vision.ee.ethz.ch)\n",
    "    This file is part of the OSVOS paper presented in:\n",
    "      Sergi Caelles, Kevis-Kokitsi Maninis, Jordi Pont-Tuset, Laura Leal-Taixe, Daniel Cremers, Luc Van Gool\n",
    "      One-Shot Video Object Segmentation\n",
    "      CVPR 2017\n",
    "    Unknown code license\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import model files\n",
    "import model\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Offline training parameters\n",
    "imagenet_ckpt = 'models/vgg_16_3chan.ckpt' # copy of checkpoint in http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz\n",
    "segnet_stream = 'fstream'\n",
    "ckpt_name= segnet_stream + '_parent'\n",
    "logs_path = os.path.join('models', ckpt_name)\n",
    "gpu_id = 0\n",
    "iter_mean_grad = 10\n",
    "max_training_iters_1 = 15000\n",
    "max_training_iters_2 = 30000\n",
    "max_training_iters_3 = 50000\n",
    "save_step = 5000\n",
    "test_image = None\n",
    "display_step = 100\n",
    "ini_learning_rate = 1e-8\n",
    "boundaries = [10000, 15000, 25000, 30000, 40000]\n",
    "values = [ini_learning_rate, ini_learning_rate * 0.1, ini_learning_rate, ini_learning_rate * 0.1, ini_learning_rate,\n",
    "          ini_learning_rate * 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load DAVIS 2016 dataset\n",
    "options = datasets._DEFAULT_DAVIS16_OPTIONS\n",
    "# Set the following to True if you have a lot of RAM\n",
    "options['data_aug'] = False\n",
    "# Set the following to wherever you have downloaded the DAVIS 2016 dataset\n",
    "dataset_root = 'E:/datasets/davis2016/' if sys.platform.startswith(\"win\") else '/media/EDrive/datasets/davis2016/'\n",
    "train_file = dataset_root + 'ImageSets/480p/train.txt'\n",
    "dataset = datasets.davis16(train_file, None, dataset_root, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset configuration\n",
    "dataset.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network with strong side outputs supervision\n",
    "with tf.Graph().as_default():\n",
    "    with tf.device('/gpu:' + str(gpu_id)):\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        learning_rate = tf.train.piecewise_constant(global_step, boundaries, values)\n",
    "        model.train_parent(dataset, imagenet_ckpt, 1, learning_rate, logs_path, max_training_iters_1, save_step,\n",
    "                           display_step, global_step, segnet_stream, iter_mean_grad=iter_mean_grad, test_image_path=test_image,\n",
    "                           ckpt_name=ckpt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network with weak side outputs supervision\n",
    "with tf.Graph().as_default():\n",
    "    with tf.device('/gpu:' + str(gpu_id)):\n",
    "        global_step = tf.Variable(max_training_iters_1, name='global_step', trainable=False)\n",
    "        learning_rate = tf.train.piecewise_constant(global_step, boundaries, values)\n",
    "        model.train_parent(dataset, imagenet_ckpt, 2, learning_rate, logs_path, max_training_iters_2, save_step,\n",
    "                           display_step, global_step, segnet_stream, iter_mean_grad=iter_mean_grad, resume_training=True,\n",
    "                           test_image_path=test_image, ckpt_name=ckpt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the network without side outputs supervision\n",
    "with tf.Graph().as_default():\n",
    "    with tf.device('/gpu:' + str(gpu_id)):\n",
    "        global_step = tf.Variable(max_training_iters_2, name='global_step', trainable=False)\n",
    "        learning_rate = tf.train.piecewise_constant(global_step, boundaries, values)\n",
    "        model.train_parent(dataset, imagenet_ckpt, 3, learning_rate, logs_path, max_training_iters_3, save_step,\n",
    "                           display_step, global_step, segnet_stream, iter_mean_grad=iter_mean_grad, resume_training=True,\n",
    "                           test_image_path=test_image, ckpt_name=ckpt_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
