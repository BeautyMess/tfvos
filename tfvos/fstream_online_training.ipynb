{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `FStream` Online Training\n",
    "\n",
    "**[THIS IS WORK IN PROGRESS]**\n",
    "\n",
    "This notebook performs online training of the **flow stream parent model** on the **car-shadow** sequence, so make sure you've run the [`FStream` Offline Training](fstream_offline_training.ipynb) notebook before running this one.\n",
    "\n",
    "\n",
    "The online training of the `FStream` network is done by finetuning the parent model **on the first frame** of the video sequence. This is the only frame for which a mask is provided. It is augmented using scaling and vertical flipping. The network is trained for 500 iterations using the same training parameters as during offline training, except that deep supervision is disabled.\n",
    "\n",
    "![](img/osvos_child.png)\n",
    "\n",
    "To monitor training, run:\n",
    "```\n",
    "tensorboard --logdir E:\\repos\\tf-video-seg\\tfvos\\models\\fstream_car-shadow\n",
    "http://localhost:6006\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fstream_online_training.ipynb\n",
    "\n",
    "FStream online trainer\n",
    "\n",
    "Written by Phil Ferriere\n",
    "\n",
    "Licensed under the MIT License (see LICENSE for details)\n",
    "\n",
    "Based on:\n",
    "  - https://github.com/scaelles/OSVOS-TensorFlow/blob/master/osvos_parent_demo.py\n",
    "    Written by Sergi Caelles (scaelles@vision.ee.ethz.ch)\n",
    "    This file is part of the OSVOS paper presented in:\n",
    "      Sergi Caelles, Kevis-Kokitsi Maninis, Jordi Pont-Tuset, Laura Leal-Taixe, Daniel Cremers, Luc Van Gool\n",
    "      One-Shot Video Object Segmentation\n",
    "      CVPR 2017\n",
    "    Unknown code license\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import model files\n",
    "import model\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model paths\n",
    "seq_name = \"car-shadow\"\n",
    "segnet_stream = 'fstream'\n",
    "parent_path = 'models/' + segnet_stream + '_parent/' + segnet_stream + '_parent-50000'\n",
    "ckpt_name = segnet_stream + '_' + seq_name\n",
    "logs_path = 'models/' + ckpt_name\n",
    "\n",
    "# Online training parameters\n",
    "gpu_id = 0\n",
    "max_training_iters = 500\n",
    "learning_rate = 1e-8\n",
    "save_step = max_training_iters\n",
    "side_supervision = 3\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the DAVIS 2016 sequence\n",
    "options = datasets._DEFAULT_DAVIS16_OPTIONS\n",
    "options['use_cache'] = False\n",
    "options['data_aug'] = True\n",
    "# Set the following to wherever you have downloaded the DAVIS 2016 dataset\n",
    "dataset_root = 'E:/datasets/davis2016/' if sys.platform.startswith(\"win\") else '/media/EDrive/datasets/davis2016/'\n",
    "test_frames = sorted(os.listdir(dataset_root + 'JPEGImages/480p/' + seq_name))\n",
    "test_imgs = [dataset_root + 'JPEGImages/480p/' + seq_name + frame) for frame in test_frames]\n",
    "train_imgs = [dataset_root + 'JPEGImages/480p/' + seq_name + '00000.jpg', \n",
    "              dataset_root + 'Annotations/480p' + seq_name + '00000.png']\n",
    "dataset = datasets.davis16(train_imgs, test_imgs, dataset_root, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display dataset configuration\n",
    "dataset.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finetune this branch of the binary segmentation network\n",
    "with tf.Graph().as_default():\n",
    "    with tf.device('/gpu:' + str(gpu_id)):\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        model.train_finetune(dataset, parent_path, side_supervision, learning_rate, logs_path, max_training_iters,\n",
    "                             save_step, display_step, global_step, segnet_stream, iter_mean_grad=1, ckpt_name=ckpt_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Result path (if you want to check how well this branch is doing on its own)\n",
    "result_path = dataset_folder + 'Results/Segmentations/480p/' + ckpt_name\n",
    "\n",
    "# Test this branch of the network\n",
    "with tf.Graph().as_default():\n",
    "    with tf.device('/gpu:' + str(gpu_id)):\n",
    "        ckpt_path = logs_path + '/' + ckpt_name + '.ckpt-' + str(max_training_iters))\n",
    "        model.test(dataset, ckpt_path, result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the original images and their predicted masks to get an idea of how this branch of the network is doing. Note that the first mask is displayed in red overlay, as it is given to us. The predicted masks are displayed using a green overlay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load results\n",
    "frames = []\n",
    "predicted_masks=[]\n",
    "for test_frame in test_frames:\n",
    "    frame_num = test_frame.split('.')[0]\n",
    "    frame = np.array(Image.open(dataset_root + 'JPEGImages/480p/' + seq_name + '/' + test_frame))\n",
    "    predicted_mask = np.array(Image.open(result_path + frame_num +'.png'))\n",
    "    frames.append(frame)\n",
    "    predicted_masks.append(predicted_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Overlay the masks on top of the frames\n",
    "frames_with_predictions = visualize.overlay_frames_with_predictions(frames, predicted_masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display individual frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualize.display_images(frames_with_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display results as a video clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set path to video clips\n",
    "video_clip_folder = dataset_root + 'clips/'\n",
    "video_clip = video_clip_folder + ckpt_name + '.mp4'\n",
    "\n",
    "# Combine images in a video clip\n",
    "visualize.make_clip(video_clip, frames_with_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display video\n",
    "visualize.show_clip(video_clip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
