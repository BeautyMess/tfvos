{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAVIS 2016 - Load and Inspect Dataset (with Augmentation)\n",
    "\n",
    "In this notebook we:\n",
    "- Load the 2016 dataset and create the additional data necessary to train MaskRNN (see below)\n",
    "- Show sample videos along with the MaskRNN additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import time\n",
    "import random\n",
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "Load the DAVIS 2016 dataset and do all the processing necessary for MaskRNN training. As you can see below, it **does** take a while!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "dataset_root = 'E:/datasets/davis2016/'\n",
    "train_file = dataset_root + 'ImageSets/480p/train.txt'\n",
    "# train_file = dataset_root + 'ImageSets/480p/train_dbg.txt'\n",
    "options = datasets._DEFAULT_DAVIS16_OPTIONS\n",
    "dataset = datasets.davis16(train_file, None, dataset_root, options)\n",
    "end = time.time()\n",
    "m, s = divmod(end - start, 60)\n",
    "h, m = divmod(m, 60)\n",
    "print('Time Taken: {:2.0f}h{:2.0f}m{:2.0f}s for {} videos (includes augmentation).'.format(h, m, s, dataset.num_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display dataset configuration\n",
    "dataset.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a few videos to inspect (includes data augmented videos) at random.\n",
    "> Naming convention example: `bear_sc_0.5_fl`, bear video scaled by 0.5 factor and flipped vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset = 3\n",
    "random.seed(1)\n",
    "videos = random.sample(list(dataset.videos.keys()), subset)\n",
    "print('Chosen videos: {} out of {} videos'.format(videos, dataset.num_videos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a list of individual video frames with:\n",
    "- groundtruth masks (red) and computed mask bounding boxes (yellow)\n",
    "- video frames with previous-frame masks (green) warped based on the optical flow measured betwwen the previous frame and the current frame, as well as the computed mask bounding box for this warped mask (yellow)\n",
    "- both combined (useful to see how \"off\" the optical flow predictions are)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show the individual video frames with groundtruth masks (red) and computed mask bounding boxes (yellow)\n",
    "frames_with_gt_masks = {}\n",
    "frames_with_warped_masks = {}\n",
    "frames_with_both_masks = {}\n",
    "for video in videos:\n",
    "    frames_with_gt_masks[video] = dataset.create_frames_with_overlays(video, mode='gt')\n",
    "    frames_with_warped_masks[video] = dataset.create_frames_with_overlays(video, mode='warped')\n",
    "    frames_with_both_masks[video] = dataset.create_frames_with_overlays(video, mode='gt_warped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display individual frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the individual video frames with groundtruth masks (red) and computed mask bounding boxes (yellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for video in videos:\n",
    "    print('{} (groundtruth):'.format(video))\n",
    "    dataset.show_frames(frames_with_gt_masks[video], video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for video in videos:\n",
    "    print('{} (warped masks from flow):'.format(video))\n",
    "    dataset.show_frames(frames_with_warped_masks[video])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for video in videos:\n",
    "    print('{} (groundtruth masks and warped masks from flow):'.format(video))\n",
    "    dataset.show_frames(frames_with_both_masks[video])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_clip_folder = dataset_root + 'clips/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the video clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Same as above, but this time turn the images into a MP4 video clip\n",
    "for video in videos:\n",
    "    print('{}'.format(video))\n",
    "    dataset.make_clip(video_clip_folder + video + '_gt.mp4', frames_with_gt_masks[video])\n",
    "    dataset.make_clip(video_clip_folder + video + '_wrp.mp4', frames_with_warped_masks[video])\n",
    "    dataset.make_clip(video_clip_folder + video + '_gt_wrp.mp4', frames_with_both_masks[video])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groundtruths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.show_clip(video_clip_folder + videos[0] + '_gt.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.show_clip(video_clip_folder + videos[1] + '_gt.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.show_clip(video_clip_folder + videos[2] + '_gt.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Masks warped by optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.show_clip(video_clip_folder + videos[0] + '_wrp.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.show_clip(video_clip_folder + videos[1] + '_wrp.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.show_clip(video_clip_folder + videos[2] + '_wrp.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Groundtruth masks and masks warped by optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.show_clip(video_clip_folder + videos[0] + '_gt_wrp.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.show_clip(video_clip_folder + videos[1] + '_gt_wrp.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.show_clip(video_clip_folder + videos[2] + '_gt_wrp.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
