{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAVIS 2016 - Load and Inspect Dataset (with Augmentation)\n",
    "\n",
    "In this notebook we:\n",
    "- Load the 2016 dataset and create the additional data necessary to train MaskRNN (see below)\n",
    "- Show sample videos along with the MaskRNN additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import random\n",
    "import datasets\n",
    "import visualize\n",
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "Load the DAVIS 2016 dataset and do all the processing necessary for MaskRNN training. This will take a while if data augmentation is enabled!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure - *SET* dataset_root to the correct path on your machine!\n",
    "dataset_root = 'E:/datasets/davis2016/' if sys.platform.startswith(\"win\") else '/media/EDrive/datasets/davis2016/'\n",
    "train_file = dataset_root + 'ImageSets/480p/train.txt'\n",
    "options = datasets._DEFAULT_DAVIS16_OPTIONS\n",
    "options['data_aug'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "start = time.time()\n",
    "dataset = datasets.davis16(train_file, None, dataset_root, options)\n",
    "end = time.time()\n",
    "m, s = divmod(end - start, 60)\n",
    "h, m = divmod(m, 60)\n",
    "print('Time Taken: {:2.0f}h{:2.0f}m{:2.0f}s for {} videos (includes augmentation time, if any).'.format(h, m, s, dataset.num_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display dataset configuration\n",
    "dataset.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a few videos to inspect (includes data augmented videos) at random.\n",
    "> Naming convention example: `bear_sc_0.5_fl`, bear video scaled by 0.5 factor and flipped vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset = 1 # Choose [1|2|3]\n",
    "random.seed(1)\n",
    "videos = random.sample(list(dataset.videos.keys()), subset)\n",
    "print('Chosen videos: {} out of {} videos'.format(videos, dataset.num_videos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a list of individual video frames with:\n",
    "- video frames overlaid with groundtruth masks (red) and computed mask bounding boxes (blue)\n",
    "- video frames overlaid with previous-frame masks (green) warped based on the optical flow measured betwwen the previous frame and the current frame, as well as the computed mask bounding box for this warped mask (yellow)\n",
    "- both combined (useful to see how \"off\" the optical flow predictions are)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show the individual video frames with groundtruth masks (red) and computed mask bounding boxes (yellow)\n",
    "frames_with_gt_masks = {}\n",
    "frames_with_warped_masks = {}\n",
    "frames_with_both_masks = {}\n",
    "for video in videos:\n",
    "    frames_with_gt_masks[video] = dataset.create_frames_with_overlays(video, mode='gt')\n",
    "    frames_with_warped_masks[video] = dataset.create_frames_with_overlays(video, mode='warped')\n",
    "    frames_with_both_masks[video] = dataset.create_frames_with_overlays(video, mode='gt_warped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display individual frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the individual video frames overlaid with groundtruth masks (red) and computed mask bounding boxes (blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for video in videos:\n",
    "    print('{} (groundtruth):'.format(video))\n",
    "    visualize.display_images(frames_with_gt_masks[video])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the overlaid with previous-frame masks (green) warped based on the optical flow measured betwwen the previous frame and the current frame, as well as the computed mask bounding box for this warped mask (yellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for video in videos:\n",
    "    print('{} (warped masks from flow):'.format(video))\n",
    "    visualize.display_images(frames_with_warped_masks[video])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show both combined (useful to see how \"off\" the optical flow predictions are)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for video in videos:\n",
    "    print('{} (groaundtruth masks and warped masks from flow):'.format(video))\n",
    "    visualize.display_images(frames_with_both_masks[video])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The content of the clips below is the same as above but rather than showing individual frames with their overlays, we re-create the entire video sequence with overlays. The clips help get a better sense of what kind of motion is displacing the warped masks away from their groundtruths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_clip_folder = dataset_root + 'clips/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the video clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Same as above, but this time turn the images into a MP4 video clip\n",
    "for video in videos:\n",
    "    print('{}'.format(video))\n",
    "    visualize.make_clip(video_clip_folder + video + '_gt.mp4', frames_with_gt_masks[video])\n",
    "    visualize.make_clip(video_clip_folder + video + '_wrp.mp4', frames_with_warped_masks[video])\n",
    "    visualize.make_clip(video_clip_folder + video + '_gt_wrp.mp4', frames_with_both_masks[video])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groundtruths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_clips = [video_clip_folder + videos[video] + '_gt.mp4' for video in range(subset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualize.show_clips(video_clips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Masks warped by optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_clips = [video_clip_folder + videos[video] + '_wrp.mp4' for video in range(subset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualize.show_clips(video_clips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Groundtruth masks and masks warped by optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_clips = [video_clip_folder + videos[video] + '_gt_wrp.mp4' for video in range(subset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize.show_clips(video_clips)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
